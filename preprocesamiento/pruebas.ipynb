{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-10T01:33:39.734632Z",
     "start_time": "2024-07-10T01:33:39.170942Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import copy\n",
    "import string\n",
    "import re\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import time\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "# Descargar los recursos necesarios de NLTK\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('punkt')\n",
    "# Cargar el modelo de lenguaje en espa침ol de spaCy\n",
    "nlp = spacy.load('es_core_news_sm')\n",
    "\n",
    "stopwords_es = stopwords.words('spanish')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "PUNCT_TO_REMOVE = string.punctuation"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\lcres\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\lcres\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\lcres\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\lcres\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T01:33:40.468335Z",
     "start_time": "2024-07-10T01:33:40.447983Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dfOriginal = pd.read_csv('C:/Users/lcres/PycharmProjects/SELENIUM/yt_comments.csv', sep = ',',low_memory=False)\n",
    "\n",
    "dataframe=copy.deepcopy(dfOriginal)\n",
    "print(dataframe.shape)\n",
    "dataframe.head(5)\n"
   ],
   "id": "4af42c540b208710",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(780, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   title                                                url  \\\n",
       "0    NaN  https://www.youtube.com/watch?v=Q6v2xdRMEzY&pp...   \n",
       "1    NaN  https://www.youtube.com/watch?v=Q6v2xdRMEzY&pp...   \n",
       "2    NaN  https://www.youtube.com/watch?v=Q6v2xdRMEzY&pp...   \n",
       "3    NaN  https://www.youtube.com/watch?v=Q6v2xdRMEzY&pp...   \n",
       "4    NaN  https://www.youtube.com/watch?v=Q6v2xdRMEzY&pp...   \n",
       "\n",
       "                                             comment  \n",
       "0  - De que trata el juego? \\n- De f칰tbol, que no...  \n",
       "1  No hubo casi sustos porque auron se tomaba las...  \n",
       "2  3 minutos y m치s de 2 zooms? Aumento de sueldo ...  \n",
       "3                       21:58 unboxing de est칩mago 游삕  \n",
       "4  La neta de los juegos q m치s disfrut칠 con Auron...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.youtube.com/watch?v=Q6v2xdRMEzY&amp;pp...</td>\n",
       "      <td>- De que trata el juego? \\n- De f칰tbol, que no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.youtube.com/watch?v=Q6v2xdRMEzY&amp;pp...</td>\n",
       "      <td>No hubo casi sustos porque auron se tomaba las...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.youtube.com/watch?v=Q6v2xdRMEzY&amp;pp...</td>\n",
       "      <td>3 minutos y m치s de 2 zooms? Aumento de sueldo ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.youtube.com/watch?v=Q6v2xdRMEzY&amp;pp...</td>\n",
       "      <td>21:58 unboxing de est칩mago 游삕</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.youtube.com/watch?v=Q6v2xdRMEzY&amp;pp...</td>\n",
       "      <td>La neta de los juegos q m치s disfrut칠 con Auron...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T01:33:41.295001Z",
     "start_time": "2024-07-10T01:33:41.284375Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataframe=dataframe.drop(['title'], axis=1)\n",
    "dataframe=dataframe.drop(['url'], axis=1)\n",
    "print(dataframe.shape)\n",
    "print(dataframe.head(10))"
   ],
   "id": "61f292035bbb36f4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(780, 1)\n",
      "                                             comment\n",
      "0  - De que trata el juego? \\n- De f칰tbol, que no...\n",
      "1  No hubo casi sustos porque auron se tomaba las...\n",
      "2  3 minutos y m치s de 2 zooms? Aumento de sueldo ...\n",
      "3                       21:58 unboxing de est칩mago 游삕\n",
      "4  La neta de los juegos q m치s disfrut칠 con Auron...\n",
      "5  El video est치 tan bien editado que no parece q...\n",
      "6  me mata como el juego censura los genitales de...\n",
      "7              6:27 \" owww , soy yo con tu mama\"  XD\n",
      "8             6:27 pense que iba a decir algo bonito\n",
      "9  Auron y los juegos de terror se complementan d...\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T01:33:42.128223Z",
     "start_time": "2024-07-10T01:33:42.120703Z"
    }
   },
   "cell_type": "code",
   "source": "dataframe[\"comment\"] = dataframe[\"comment\"].str.lower()",
   "id": "1bcfa9e7772261f8",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T01:33:43.271009Z",
     "start_time": "2024-07-10T01:33:43.260234Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "# Funci칩n para remover puntuaci칩n\n",
    "def remove_punctuation(text):\n",
    "    return text.translate(str.maketrans('', '', PUNCT_TO_REMOVE))\n",
    "# Funci칩n para tokenizar el texto\n",
    "def tokenize_text(text):\n",
    "    # Handle non-string values\n",
    "    if not isinstance(text, str):\n",
    "        return []  # Or handle the non-string value as needed\n",
    "    return word_tokenize(text)\n",
    "\n",
    "# Funci칩n para limpiar el texto\n",
    "\n",
    "def clean_text(tokens):\n",
    "    text = \" \".join(tokens)\n",
    "    # Eliminar URLs\n",
    "    text = re.sub(r'http\\S+|www.\\S+', '', text, flags=re.MULTILINE)\n",
    "    # Eliminar emojis (opci칩n mejorada que no elimina tildes)\n",
    "    text = re.sub(r'[^\\w\\s,]', '', text, flags=re.UNICODE)\n",
    "    # Eliminar n칰meros\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    # Eliminar puntuaci칩n\n",
    "    text = remove_punctuation(text)\n",
    "    words = text.split()\n",
    "    # Filtrar palabras vac칤as\n",
    "    filtered_words = [word for word in words if word.lower() not in stopwords_es]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    doc = nlp(text)\n",
    "    lemmatized_words = [token.lemma_ for token in doc]\n",
    "    return ' '.join(lemmatized_words)\n",
    "# Funci칩n para procesar un bloque del DataFrame\n",
    "def process_block(block):\n",
    "    print(\"Procesando..............\")\n",
    "    # Handle potential non-string values in 'comment' column\n",
    "    block['comment'] = block['comment'].astype(str)  # Convert to string type\n",
    "    block['comment_tokenized'] = block['comment'].apply(tokenize_text)\n",
    "    print(\"Texto tokenizado\")\n",
    "    block['comment_cleaned'] = block['comment_tokenized'].apply(clean_text)\n",
    "    print(\"Texto limpio\")\n",
    "    block['comment_lemmatized'] = block['comment_cleaned'].apply(lemmatize_text)\n",
    "    print(\"Texto lematizado\")\n",
    "    return block"
   ],
   "id": "256da6273852d238",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-07-10T01:33:44.743228Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Dividir el DataFrame en bloques y procesar en paralelo\n",
    "num_blocks = cpu_count()\n",
    "blocks = [dataframe.iloc[i::num_blocks] for i in range(num_blocks)]\n",
    "with Pool(num_blocks) as pool:\n",
    "    result_blocks = pool.map(process_block, blocks)\n",
    "\n",
    "result_df = pd.concat(result_blocks)\n",
    "result_df.head(10)"
   ],
   "id": "a6967db7869a063f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4db45aa90114e707"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
